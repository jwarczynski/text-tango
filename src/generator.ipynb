{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T08:14:27.901564Z",
     "start_time": "2024-05-07T08:14:27.779962Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from program import Program, ProgramWriter\n",
    "from lm_poller import LMPoller\n",
    "from text_preprocessing import extract_triplets, extract_relations\n",
    "from lm_response_evaluator import extract_code, get_response_similarity, evaluate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89b2b31d792e2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T08:14:27.981334Z",
     "start_time": "2024-05-07T08:14:27.902651Z"
    }
   },
   "outputs": [],
   "source": [
    "#read json file from ../res/webnlg/train.json\n",
    "with open('../res/webnlg/train.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# print(data['data'][0]['in'])\n",
    "# print(len(data['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d1820cd1320491e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T08:14:28.036832Z",
     "start_time": "2024-05-07T08:14:27.982302Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for i in range(len(data['data'])):\n",
    "    sample = data['data'][i]\n",
    "    in_data = data['data'][i]['in']\n",
    "    relations = extract_relations(in_data)\n",
    "    relations = tuple(relations)\n",
    "\n",
    "    if relations in data_dict:\n",
    "        data_dict[relations].append(sample)\n",
    "    else:\n",
    "        data_dict[relations] = [sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a91c0fe1b3a49c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T08:14:28.040312Z",
     "start_time": "2024-05-07T08:14:28.038100Z"
    }
   },
   "outputs": [],
   "source": [
    "keys = list(data_dict.keys())\n",
    "example_id = -1\n",
    "# print(f'{keys[example_id]}:\\n {data_dict[keys[example_id]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d48e820607d21fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T08:14:28.048116Z",
     "start_time": "2024-05-07T08:14:28.044360Z"
    }
   },
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger('lm_poller')\n",
    "\n",
    "def log_error(message):\n",
    "    logger.error(message)\n",
    "\n",
    "MAX_LLM_FIX_QUYERY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ca62a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: None\n",
      "similarity: 1.0\n",
      "output: Alpena County Regional Airport owner is Alpena County, Michigan.\n",
      "reference: Alpena County Regional Airport owner is Alpena County, Michigan.\n",
      "\n",
      "\n",
      "Errors: None\n",
      "similarity: 0.725\n",
      "output: The 1st runway length metres of the 1st at Amsterdam Airport Schiphol is 3800 metre.\n",
      "reference: The length of the first runway at Amsterdam Airport Schiphol is 3800 metres.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SimpleProgramTrainer()\n\u001b[1;32m      7\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(d)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_program\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../out\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprogram\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lnet/troja/work/people/lango/text-tango/src/program.py:61\u001b[0m, in \u001b[0;36mProgram.write_program\u001b[0;34m(self, output_dir, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_program\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_dir, name):\n\u001b[0;32m---> 61\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mProgramWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrules\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     63\u001b[0m         writer\u001b[38;5;241m.\u001b[39madd_rule_if_stmt(rule\u001b[38;5;241m.\u001b[39mrelation_set)\n",
      "File \u001b[0;32m/lnet/troja/work/people/lango/text-tango/src/program.py:75\u001b[0m, in \u001b[0;36mProgramWriter.__init__\u001b[0;34m(self, output_dir, name)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogram \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__add_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lnet/troja/work/people/lango/text-tango/src/program.py:79\u001b[0m, in \u001b[0;36mProgramWriter.__add_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# read header from file and add to program\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     header_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(header_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     81\u001b[0m         header \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "from trainer import SimpleProgramTrainer\n",
    "d = {}\n",
    "for i, key in enumerate(keys[20:22]):\n",
    "    d[key] = data_dict[key]\n",
    "\n",
    "trainer = SimpleProgramTrainer()\n",
    "trainer.train(d)\n",
    "trainer.program.write_program('../out','program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c4a679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/lango/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/lango/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/lango/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "/home/lango/personal_work_troja/software/miniconda3/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for gem contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/gem\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR: 0.024135570864320017 \n",
      "BLEU: 0.0 \n"
     ]
    }
   ],
   "source": [
    "from evaluate_program import BERTScore, evaluate_program, get_basic_metrics\n",
    "evaluate_program(trainer.program, get_basic_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a86e45e6973d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T08:14:36.327107Z",
     "start_time": "2024-05-07T08:14:28.049062Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Program.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m program_gen \u001b[38;5;241m=\u001b[39m \u001b[43mProgram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../out/program\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m lm \u001b[38;5;241m=\u001b[39m LMPoller()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(keys[\u001b[38;5;241m20\u001b[39m:\u001b[38;5;241m22\u001b[39m]):\n",
      "\u001b[0;31mTypeError\u001b[0m: Program.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "program_gen = ProgramWriter('../out/program')\n",
    "lm = LMPoller()\n",
    "\n",
    "for i, key in enumerate(keys[20:22]):\n",
    "    relations = set(key)\n",
    "    program_gen.add_rule_if_stmt(set(key))\n",
    "    #get sample for the key\n",
    "    sample = data_dict[key][0]\n",
    "    sample_X = sample['in']\n",
    "    reference_text = sample['out']\n",
    "    triplets = extract_triplets(sample_X)\n",
    "    \n",
    "    # print(f'key: {key}, triplets: {triplets}, relations: {relations}')\n",
    "    \n",
    "    response = lm.query_lm(triplets, reference_text, relations)\n",
    "    with open(f'../res/lama_responses/response_{i}.txt', 'w') as f:\n",
    "        f.write(response)\n",
    "    exctracted_code = extract_code(response, relations)\n",
    "    with open(f'../res/lama_responses/code_{i}.py', 'w') as f:\n",
    "        f.write(exctracted_code)\n",
    "    \n",
    "    output, errors = evaluate_response(triplets ,exctracted_code, reference_text, relations)\n",
    "    print(f'Errors: {errors}')\n",
    "    fix_query_count = 0\n",
    "    print(f'similarity: {get_response_similarity(output, reference_text)}')\n",
    "    print(f'output: {output}\\nreference: {reference_text}\\n\\n')\n",
    "    while (errors is not None or get_response_similarity(output, reference_text) < 0.5) and fix_query_count < MAX_LLM_FIX_QUYERY:\n",
    "        response = lm.fix_query(output, errors)\n",
    "        exctracted_code = extract_code(response, relations)\n",
    "        output, errors = evaluate_response(triplets, exctracted_code, reference_text)\n",
    "        fix_query_count += 1\n",
    "        \n",
    "    if fix_query_count < MAX_LLM_FIX_QUYERY:\n",
    "        program_gen.add_rule(exctracted_code)\n",
    "    else:\n",
    "        log_error(f'Failed to generate rule for {key} after {MAX_LLM_FIX_QUYERY} attempts. Skipping...')\n",
    "        \n",
    "\n",
    "program_gen.add_print_stmt()\n",
    "program_gen.write_program()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
